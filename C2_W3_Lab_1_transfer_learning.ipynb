{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "C2_W3_Lab_1_transfer_learning.ipynb",
            "private_outputs": true,
            "provenance": [
                {
                    "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W3/ungraded_labs/C2_W3_Lab_1_transfer_learning.ipynb",
                    "timestamp": 1639668234563
                }
            ],
            "toc_visible": true
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W3/ungraded_lab/C2_W3_Lab_1_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ],
            "metadata": {
                "azdata_cell_guid": "6f0586d0-4496-4cb6-86eb-dc26b3ffc193"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Ungraded Lab: Transfer Learning\n",
                "\n",
                "In this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n",
                "\n",
                "1. just get the convolution layers of one model\n",
                "2. attach some dense layers onto it\n",
                "3. train just the dense network\n",
                "4. evaluate the results\n",
                "\n",
                "Doing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections."
            ],
            "metadata": {
                "id": "bT0to3TL2q7H",
                "azdata_cell_guid": "df4e0fe5-8f08-4f69-932f-48e4f12e4d69"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors."
            ],
            "metadata": {
                "id": "Qvrr8pLRzJMV",
                "azdata_cell_guid": "e803777e-2990-4959-96e6-dc829201ff98"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Setup the pretrained model\n",
                "\n",
                "You will need to prepare pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n",
                "\n",
                "1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n",
                "\n",
                "2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n",
                "\n",
                "3. Add dense layers which you will train.\n",
                "\n",
                "Let's see how to do these in the next cells."
            ],
            "metadata": {
                "id": "-12slkPL6_JH",
                "azdata_cell_guid": "83882d8e-5109-47c8-879c-55a4a160c7a0"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already."
            ],
            "metadata": {
                "id": "3VqhFEK2Y-PK",
                "azdata_cell_guid": "df7907e2-47f6-42de-902f-1aaee5651338"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
                "!wget --no-check-certificate \\\n",
                "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
                "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
            ],
            "metadata": {
                "id": "1xJZ5glPPCRz",
                "azdata_cell_guid": "4aef0ad1-ab04-4885-bfd5-eeb516ade5de"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
                "from tensorflow.keras import layers\n",
                "\n",
                "# Set the weights file you downloaded into a variable\n",
                "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
                "\n",
                "# Initialize the base model.\n",
                "# Set the input shape and remove the dense layers.\n",
                "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
                "                                include_top = False, \n",
                "                                weights = None)\n",
                "\n",
                "# Load the pre-trained weights you downloaded.\n",
                "pre_trained_model.load_weights(local_weights_file)\n",
                "\n",
                "# Freeze the weights of the layers.\n",
                "for layer in pre_trained_model.layers:\n",
                "  layer.trainable = False"
            ],
            "metadata": {
                "id": "KsiBCpQ1VvPp",
                "azdata_cell_guid": "81d4c1e2-3a54-487c-b2b0-0fcd3028e098"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed_7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed_7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get."
            ],
            "metadata": {
                "id": "1y2rEnqFaa9k",
                "azdata_cell_guid": "04642bd9-dcf0-44d8-b034-628251aee52f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "pre_trained_model.summary()\n"
            ],
            "metadata": {
                "id": "qeGP0Ust5kCR",
                "azdata_cell_guid": "3c6d298d-6144-4cc0-9153-b968a740df89"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# Choose `mixed_7` as the last layer of your base model\n",
                "last_layer = pre_trained_model.get_layer('mixed7')\n",
                "print('last layer output shape: ', last_layer.output_shape)\n",
                "last_output = last_layer.output\n",
                "# last_output should be the output from the layer selected as the last one desired\n",
                "  # Then, the object to be referrenced is now 'last_layer'."
            ],
            "metadata": {
                "id": "jDmGO9tg5iPc",
                "azdata_cell_guid": "59508b63-087a-4065-aa1a-0dc8f0ac2261"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Add dense layers for your classifier\n",
                "\n",
                "Next, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting."
            ],
            "metadata": {
                "id": "UXT9SDMK7Ioa",
                "azdata_cell_guid": "de1fd037-b1dc-47ad-9a3e-6651c79918dc"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from tensorflow.keras.optimizers import RMSprop\n",
                "from tensorflow.keras import Model\n",
                "# Here, we must use the Tensorflow's Functional API, instead of the traditional\n",
                "# Sequential model API because the original model that we are importing for\n",
                "# transfer learning was created using it.\n",
                "# If we print the type of the pre-trained model as:\n",
                "# print(f\"The pretrained model has type: {type(pre_trained_model)}\")\n",
                "# The following output is obtained, showing that the Functional API was used, \n",
                "# In this API, layers are declared as functions applied in sequence \n",
                "# to an input X. It is totally equivalent to the traditional API, though.\n",
                "  \n",
                "# Flatten the output layer to 1 dimension\n",
                "# Flatten the results to feed into a DNN\n",
                "# Convert the images to 1-dimension NumPy arrays to be processed by the dense\n",
                "# neural networks.\n",
                "# The input used in Flatten must be the last output of the pre-trained model.\n",
                "# We manually set is as 'mixed7', instead of the the last layer of the model.\n",
                "x = layers.Flatten()(last_output)\n",
                "# Now, x will be the input for the next layer. We can save the obtained output\n",
                "# again as x, creating a Sequential model (the inputs flow in sequence to the\n",
                "# defined networks).\n",
                "\n",
                "# Add a fully connected layer with 1024 hidden units and ReLU activation\n",
                "x = layers.Dense(1024, activation='relu')(x)\n",
                "# Add a dropout rate of 0.2\n",
                "x = layers.Dropout(0.2)(x)\n",
                "# It ramdomly removes 20% of the weights of the dense neural networks to avoid\n",
                "# overfitting. Close neurons may show approximately equal weights due to overfitting,\n",
                "# emphasizing wrong features. Image classification problems are particularly prone to\n",
                "# it, even with image augmentation. So, the Dropout is an important technique\n",
                "# to avoid overfitting in deep learning models, specially for image classification.\n",
                "\n",
                "# Add a final sigmoid layer for classification\n",
                "x = layers.Dense  (1, activation='sigmoid')(x)\n",
                "# Only 1 output neuron. That is because we are dealing with a BINARY classification problem\n",
                "# where the output gets a value from 0-1 (representing a probability) for an image belonging to\n",
                "# a given class. We label the images as 0 for one class ('humans'); and as 1 for the other ('horses',\n",
                "# or vice-versa).\n",
                "# Remember that the last dense layer should have a number of neurons equals to the number of\n",
                "# possible classes. For regression problems, the output is a scalar (a 1-dimensional number), so the\n",
                "# last dense layer must have a single neuron. For a multi-classification problem with N classes,\n",
                "# we should have N neurons activated through 'softmax' in the last dense layer. Therefore, we could\n",
                "# use here a Dense(2, activation = 'softmax'). On the other hand, the Dense(1, activation = 'sigmoid')\n",
                "# is equivalent to the logistic regression and shows better performance for the binary classification\n",
                "# then the Dense(2, activation = 'softmax') layer.\n",
                "# Notice, though, that the use of Dense(1, activation = 'sigmoid') in classifications is restricted to\n",
                "# the situation where we have only two classes. For more (N) classes, use Dense(N, activation = 'softmax').       \n",
                "\n",
                "# Append the dense network to the base model\n",
                "# Create the complete model by using the Model class\n",
                "model =  Model(pre_trained_model.input, x)\n",
                "# Again, we must use this class because the model was obtained with TensorFlow's Functional API.\n",
                "# We pass the pre-trained model's input and x (the inputs and outputs of our own Dense sequential\n",
                "# model) to it.\n",
                "# The last layers are more specific for the particular classification problem to which the model is \n",
                "# being trained, whereas the first convolutions are more general, destined to capture important features\n",
                "# of data. \n",
                "  \n",
                "# Then, we use the first convolutions obtained for a very broader dataset, which will have a wider\n",
                "# diversity of information than ours, and combine it to dense layers trained for our particular situation.\n",
                "# Then, even if the original model was trained for a different number of classes, we can simply adjust the total\n",
                "# of neurons on the last dense (or use Dense(1) activated through 'sigmoid' for the binary classification)\n",
                "# to our situation: the combined model will apply the general features learned when training the original\n",
                "# model and perform specific adjusts for our own problem, like using the correct number of classifications,\n",
                "# or acquiring a better capability on classifying the particular characteristics of the elements on our\n",
                "# dataset, which may be very different from the one used on the original training.\n",
                "  \n",
                "# This methodology saves time and computational resources that may be not available, since we are using a\n",
                "# a model previously trained with better resources and through a very longer time.  \n",
                "\n",
                "# Print the model summary. See your dense network connected at the end.\n",
                "model.summary()"
            ],
            "metadata": {
                "id": "BMXb913pbvFg",
                "azdata_cell_guid": "f3a93193-549b-418e-98cf-8b563406ab7e"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "# Set the training parameters\n",
                "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
                "              loss = 'binary_crossentropy', \n",
                "              metrics = ['accuracy'])\n",
                "\n",
                "# 'adam' optimizer would automatically adjust the\n",
                "#learning rates, i.e., the rate of correction of the weights.\n",
                "#In the beginning, a too high learning rate leads to very intense errors and\n",
                "#difficulty on finding the optimum. So, in the beginning, the learning rate \n",
                "#should be low until the model finds the best direction for adjusting its parameters.\n",
                "#On the other hand, at the end of the process, the learning rate should be increased.\n",
                "#If not, the model would adjust its weights in a very low rate, and would show very\n",
                "#few improvement from one epoch to the other.\n",
                "#RMSProp does not allow us to adjust the learning rate during training, but 'adam' does\n",
                "#that for us.\n",
                "\n",
                "# To track the image throughout the neural networks, call the model.summary() method and print it:\n",
                "## print(model.summary())\n",
                "# Alternatively, simply call the function and declares in another cell:\n",
                "## model.summary()\n",
                "# Notice that, for printing the whole track of the image, this method must have no arguments, \n",
                "# so it should be declared with empty parameters."
            ],
            "metadata": {
                "id": "SAwTTkWr56uC",
                "azdata_cell_guid": "f0e6e7fd-66e6-418c-b5af-b5cee1563385"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Prepare the dataset\n",
                "\n",
                "Now you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab."
            ],
            "metadata": {
                "id": "aYLGw_RO7Z_X",
                "azdata_cell_guid": "f122e56b-d9d9-4e24-a608-217e3e5a5ad0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Download the dataset\n",
                "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
            ],
            "metadata": {
                "id": "O4s8HckqGlnb",
                "azdata_cell_guid": "95ada2ca-0f00-45c8-b44f-9fa3ab20ebb0"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "import zipfile\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# Extract the archive\n",
                "zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
                "zip_ref.extractall(\"tmp/\")\n",
                "zip_ref.close()\n",
                "\n",
                "# Define our example directories and files\n",
                "base_dir = 'tmp/cats_and_dogs_filtered'\n",
                "\n",
                "train_dir = os.path.join( base_dir, 'train')\n",
                "validation_dir = os.path.join( base_dir, 'validation')\n",
                "\n",
                "# Directory with training cat pictures\n",
                "train_cats_dir = os.path.join(train_dir, 'cats') \n",
                "\n",
                "# Directory with training dog pictures\n",
                "train_dogs_dir = os.path.join(train_dir, 'dogs') \n",
                "\n",
                "# Directory with validation cat pictures\n",
                "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
                "\n",
                "# Directory with validation dog pictures\n",
                "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
                "\n",
                "# Add our data-augmentation parameters to ImageDataGenerator\n",
                "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
                "                                   rotation_range = 40,\n",
                "                                   width_shift_range = 0.2,\n",
                "                                   height_shift_range = 0.2,\n",
                "                                   shear_range = 0.2,\n",
                "                                   zoom_range = 0.2,\n",
                "                                   horizontal_flip = True)\n",
                "\n",
                "# Note that the validation data should not be augmented!\n",
                "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
                "\n",
                "# Flow training images in batches of 20 using train_datagen generator\n",
                "train_generator = train_datagen.flow_from_directory(train_dir,\n",
                "                                                    batch_size = 20,\n",
                "                                                    class_mode = 'binary', \n",
                "                                                    target_size = (150, 150))     \n",
                "\n",
                "# Flow validation images in batches of 20 using test_datagen generator\n",
                "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
                "                                                          batch_size  = 20,\n",
                "                                                          class_mode  = 'binary', \n",
                "                                                          target_size = (150, 150))"
            ],
            "metadata": {
                "id": "WOV8jON3c3Jv",
                "azdata_cell_guid": "d9981bac-55c0-491b-bace-2e17fe877b82"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Train the model\n",
                "\n",
                "With that, you can now train the model. You will do 20 epochs and plot the results afterwards."
            ],
            "metadata": {
                "id": "3m3S6AZb7h-B",
                "azdata_cell_guid": "0003efc2-5ae8-4a08-a499-669282424591"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Train the model.\n",
                "history = model.fit(\n",
                "            train_generator,\n",
                "            validation_data = validation_generator,\n",
                "            steps_per_epoch = 100,\n",
                "            epochs = 20,\n",
                "            validation_steps = 50,\n",
                "            verbose = 2)"
            ],
            "metadata": {
                "id": "Blhq2MAUeyGA",
                "azdata_cell_guid": "7b1b40be-25b7-4cd7-99ef-19111a1de2ec"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Evaluate the results\n",
                "\n",
                "You will use the same code to plot the results. As you can see, the validation accuracy is also trending upwards as your training accuracy improves. This is a good sign that your model is no longer overfitting!"
            ],
            "metadata": {
                "id": "RwcB2bPj7lIx",
                "azdata_cell_guid": "120b7d25-38a7-4a5b-8216-2b8a26f951d2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import matplotlib.pyplot as plt\n",
                "acc = history.history['accuracy']\n",
                "val_acc = history.history['val_accuracy']\n",
                "loss = history.history['loss']\n",
                "val_loss = history.history['val_loss']\n",
                "\n",
                "epochs = range(len(acc))\n",
                "\n",
                "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
                "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
                "plt.title('Training and validation accuracy')\n",
                "plt.legend(loc=0)\n",
                "plt.figure()\n",
                "\n",
                "\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "C2Fp6Se9rKuL",
                "azdata_cell_guid": "31c24ecd-c662-4168-8929-8c242b7ced6b"
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}